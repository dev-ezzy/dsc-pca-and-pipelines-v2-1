{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Integrating PCA in Pipelines - Lab"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{},"source":["In a previous section, you learned about how to use pipelines in scikit-learn to combine several supervised learning algorithms in a manageable pipeline. In this lesson, you will integrate PCA along with classifiers in the pipeline. "]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n","\n","In this lab you will: \n","\n","- Integrate PCA in scikit-learn pipelines "]},{"cell_type":"markdown","metadata":{},"source":["## The Data Science Workflow"]},{"cell_type":"markdown","metadata":{},"source":["You will be following the data science workflow:\n","\n","1. Initial data inspection, exploratory data analysis, and cleaning\n","2. Feature engineering and selection\n","3. Create a baseline model\n","4. Create a machine learning pipeline and compare results with the baseline model\n","5. Interpret the model and draw conclusions"]},{"cell_type":"markdown","metadata":{},"source":["##  Initial data inspection, exploratory data analysis, and cleaning"]},{"cell_type":"markdown","metadata":{},"source":["You'll use a dataset created by the Otto group, which was also used in a [Kaggle competition](https://www.kaggle.com/c/otto-group-product-classification-challenge/data). The description of the dataset is as follows:\n","\n","The Otto Group is one of the world’s biggest e-commerce companies, with subsidiaries in more than 20 countries, including Crate & Barrel (USA), Otto.de (Germany) and 3 Suisses (France). They are selling millions of products worldwide every day, with several thousand products being added to their product line.\n","\n","A consistent analysis of the performance of their products is crucial. However, due to their global infrastructure, many identical products get classified differently. Therefore, the quality of product analysis depends heavily on the ability to accurately cluster similar products. The better the classification, the more insights the Otto Group can generate about their product range.\n","\n","In this lab, you'll use a dataset containing:\n","- A column `id`, which is an anonymous id unique to a product\n","- 93 columns `feat_1`, `feat_2`, ..., `feat_93`, which are the various features of a product\n","- a column `target` - the class of a product\n","\n","\n","\n","The dataset is stored in the `'otto_group.csv'` file. Import this file into a DataFrame called `data`, and then: \n","\n","- Check for missing values \n","- Check the distribution of columns \n","- ... and any other things that come to your mind to explore the data "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>feat_1</th>\n","      <th>feat_2</th>\n","      <th>feat_3</th>\n","      <th>feat_4</th>\n","      <th>feat_5</th>\n","      <th>feat_6</th>\n","      <th>feat_7</th>\n","      <th>feat_8</th>\n","      <th>feat_9</th>\n","      <th>...</th>\n","      <th>feat_85</th>\n","      <th>feat_86</th>\n","      <th>feat_87</th>\n","      <th>feat_88</th>\n","      <th>feat_89</th>\n","      <th>feat_90</th>\n","      <th>feat_91</th>\n","      <th>feat_92</th>\n","      <th>feat_93</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Class_1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Class_1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Class_1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Class_1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Class_1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 95 columns</p>\n","</div>"],"text/plain":["   id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n","0   1       1       0       0       0       0       0       0       0       0   \n","1   2       0       0       0       0       0       0       0       1       0   \n","2   3       0       0       0       0       0       0       0       1       0   \n","3   4       1       0       0       1       6       1       5       0       0   \n","4   5       0       0       0       0       0       0       0       0       0   \n","\n","   ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  feat_91  \\\n","0  ...        1        0        0        0        0        0        0   \n","1  ...        0        0        0        0        0        0        0   \n","2  ...        0        0        0        0        0        0        0   \n","3  ...        0        1        2        0        0        0        0   \n","4  ...        1        0        0        0        0        1        0   \n","\n","   feat_92  feat_93   target  \n","0        0        0  Class_1  \n","1        0        0  Class_1  \n","2        0        0  Class_1  \n","3        0        0  Class_1  \n","4        0        0  Class_1  \n","\n","[5 rows x 95 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","#importing modules\n","import pandas as pd\n","import numpy as np\n","#reading data\n","data = pd.read_csv(\"otto_group.csv\")\n","#checking the first 5 columns\n","data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 61878 entries, 0 to 61877\n","Data columns (total 95 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   id       61878 non-null  int64 \n"," 1   feat_1   61878 non-null  int64 \n"," 2   feat_2   61878 non-null  int64 \n"," 3   feat_3   61878 non-null  int64 \n"," 4   feat_4   61878 non-null  int64 \n"," 5   feat_5   61878 non-null  int64 \n"," 6   feat_6   61878 non-null  int64 \n"," 7   feat_7   61878 non-null  int64 \n"," 8   feat_8   61878 non-null  int64 \n"," 9   feat_9   61878 non-null  int64 \n"," 10  feat_10  61878 non-null  int64 \n"," 11  feat_11  61878 non-null  int64 \n"," 12  feat_12  61878 non-null  int64 \n"," 13  feat_13  61878 non-null  int64 \n"," 14  feat_14  61878 non-null  int64 \n"," 15  feat_15  61878 non-null  int64 \n"," 16  feat_16  61878 non-null  int64 \n"," 17  feat_17  61878 non-null  int64 \n"," 18  feat_18  61878 non-null  int64 \n"," 19  feat_19  61878 non-null  int64 \n"," 20  feat_20  61878 non-null  int64 \n"," 21  feat_21  61878 non-null  int64 \n"," 22  feat_22  61878 non-null  int64 \n"," 23  feat_23  61878 non-null  int64 \n"," 24  feat_24  61878 non-null  int64 \n"," 25  feat_25  61878 non-null  int64 \n"," 26  feat_26  61878 non-null  int64 \n"," 27  feat_27  61878 non-null  int64 \n"," 28  feat_28  61878 non-null  int64 \n"," 29  feat_29  61878 non-null  int64 \n"," 30  feat_30  61878 non-null  int64 \n"," 31  feat_31  61878 non-null  int64 \n"," 32  feat_32  61878 non-null  int64 \n"," 33  feat_33  61878 non-null  int64 \n"," 34  feat_34  61878 non-null  int64 \n"," 35  feat_35  61878 non-null  int64 \n"," 36  feat_36  61878 non-null  int64 \n"," 37  feat_37  61878 non-null  int64 \n"," 38  feat_38  61878 non-null  int64 \n"," 39  feat_39  61878 non-null  int64 \n"," 40  feat_40  61878 non-null  int64 \n"," 41  feat_41  61878 non-null  int64 \n"," 42  feat_42  61878 non-null  int64 \n"," 43  feat_43  61878 non-null  int64 \n"," 44  feat_44  61878 non-null  int64 \n"," 45  feat_45  61878 non-null  int64 \n"," 46  feat_46  61878 non-null  int64 \n"," 47  feat_47  61878 non-null  int64 \n"," 48  feat_48  61878 non-null  int64 \n"," 49  feat_49  61878 non-null  int64 \n"," 50  feat_50  61878 non-null  int64 \n"," 51  feat_51  61878 non-null  int64 \n"," 52  feat_52  61878 non-null  int64 \n"," 53  feat_53  61878 non-null  int64 \n"," 54  feat_54  61878 non-null  int64 \n"," 55  feat_55  61878 non-null  int64 \n"," 56  feat_56  61878 non-null  int64 \n"," 57  feat_57  61878 non-null  int64 \n"," 58  feat_58  61878 non-null  int64 \n"," 59  feat_59  61878 non-null  int64 \n"," 60  feat_60  61878 non-null  int64 \n"," 61  feat_61  61878 non-null  int64 \n"," 62  feat_62  61878 non-null  int64 \n"," 63  feat_63  61878 non-null  int64 \n"," 64  feat_64  61878 non-null  int64 \n"," 65  feat_65  61878 non-null  int64 \n"," 66  feat_66  61878 non-null  int64 \n"," 67  feat_67  61878 non-null  int64 \n"," 68  feat_68  61878 non-null  int64 \n"," 69  feat_69  61878 non-null  int64 \n"," 70  feat_70  61878 non-null  int64 \n"," 71  feat_71  61878 non-null  int64 \n"," 72  feat_72  61878 non-null  int64 \n"," 73  feat_73  61878 non-null  int64 \n"," 74  feat_74  61878 non-null  int64 \n"," 75  feat_75  61878 non-null  int64 \n"," 76  feat_76  61878 non-null  int64 \n"," 77  feat_77  61878 non-null  int64 \n"," 78  feat_78  61878 non-null  int64 \n"," 79  feat_79  61878 non-null  int64 \n"," 80  feat_80  61878 non-null  int64 \n"," 81  feat_81  61878 non-null  int64 \n"," 82  feat_82  61878 non-null  int64 \n"," 83  feat_83  61878 non-null  int64 \n"," 84  feat_84  61878 non-null  int64 \n"," 85  feat_85  61878 non-null  int64 \n"," 86  feat_86  61878 non-null  int64 \n"," 87  feat_87  61878 non-null  int64 \n"," 88  feat_88  61878 non-null  int64 \n"," 89  feat_89  61878 non-null  int64 \n"," 90  feat_90  61878 non-null  int64 \n"," 91  feat_91  61878 non-null  int64 \n"," 92  feat_92  61878 non-null  int64 \n"," 93  feat_93  61878 non-null  int64 \n"," 94  target   61878 non-null  object\n","dtypes: int64(94), object(1)\n","memory usage: 44.8+ MB\n"]}],"source":["#info\n","data.info()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>feat_1</th>\n","      <th>feat_2</th>\n","      <th>feat_3</th>\n","      <th>feat_4</th>\n","      <th>feat_5</th>\n","      <th>feat_6</th>\n","      <th>feat_7</th>\n","      <th>feat_8</th>\n","      <th>feat_9</th>\n","      <th>...</th>\n","      <th>feat_84</th>\n","      <th>feat_85</th>\n","      <th>feat_86</th>\n","      <th>feat_87</th>\n","      <th>feat_88</th>\n","      <th>feat_89</th>\n","      <th>feat_90</th>\n","      <th>feat_91</th>\n","      <th>feat_92</th>\n","      <th>feat_93</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>61878.000000</td>\n","      <td>61878.00000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>...</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","      <td>61878.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>30939.500000</td>\n","      <td>0.38668</td>\n","      <td>0.263066</td>\n","      <td>0.901467</td>\n","      <td>0.779081</td>\n","      <td>0.071043</td>\n","      <td>0.025696</td>\n","      <td>0.193704</td>\n","      <td>0.662433</td>\n","      <td>1.011296</td>\n","      <td>...</td>\n","      <td>0.070752</td>\n","      <td>0.532306</td>\n","      <td>1.128576</td>\n","      <td>0.393549</td>\n","      <td>0.874915</td>\n","      <td>0.457772</td>\n","      <td>0.812421</td>\n","      <td>0.264941</td>\n","      <td>0.380119</td>\n","      <td>0.126135</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>17862.784315</td>\n","      <td>1.52533</td>\n","      <td>1.252073</td>\n","      <td>2.934818</td>\n","      <td>2.788005</td>\n","      <td>0.438902</td>\n","      <td>0.215333</td>\n","      <td>1.030102</td>\n","      <td>2.255770</td>\n","      <td>3.474822</td>\n","      <td>...</td>\n","      <td>1.151460</td>\n","      <td>1.900438</td>\n","      <td>2.681554</td>\n","      <td>1.575455</td>\n","      <td>2.115466</td>\n","      <td>1.527385</td>\n","      <td>4.597804</td>\n","      <td>2.045646</td>\n","      <td>0.982385</td>\n","      <td>1.201720</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>15470.250000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>30939.500000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>46408.750000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>61878.000000</td>\n","      <td>61.00000</td>\n","      <td>51.000000</td>\n","      <td>64.000000</td>\n","      <td>70.000000</td>\n","      <td>19.000000</td>\n","      <td>10.000000</td>\n","      <td>38.000000</td>\n","      <td>76.000000</td>\n","      <td>43.000000</td>\n","      <td>...</td>\n","      <td>76.000000</td>\n","      <td>55.000000</td>\n","      <td>65.000000</td>\n","      <td>67.000000</td>\n","      <td>30.000000</td>\n","      <td>61.000000</td>\n","      <td>130.000000</td>\n","      <td>52.000000</td>\n","      <td>19.000000</td>\n","      <td>87.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 94 columns</p>\n","</div>"],"text/plain":["                 id       feat_1        feat_2        feat_3        feat_4  \\\n","count  61878.000000  61878.00000  61878.000000  61878.000000  61878.000000   \n","mean   30939.500000      0.38668      0.263066      0.901467      0.779081   \n","std    17862.784315      1.52533      1.252073      2.934818      2.788005   \n","min        1.000000      0.00000      0.000000      0.000000      0.000000   \n","25%    15470.250000      0.00000      0.000000      0.000000      0.000000   \n","50%    30939.500000      0.00000      0.000000      0.000000      0.000000   \n","75%    46408.750000      0.00000      0.000000      0.000000      0.000000   \n","max    61878.000000     61.00000     51.000000     64.000000     70.000000   \n","\n","             feat_5        feat_6        feat_7        feat_8        feat_9  \\\n","count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n","mean       0.071043      0.025696      0.193704      0.662433      1.011296   \n","std        0.438902      0.215333      1.030102      2.255770      3.474822   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n","max       19.000000     10.000000     38.000000     76.000000     43.000000   \n","\n","       ...       feat_84       feat_85       feat_86       feat_87  \\\n","count  ...  61878.000000  61878.000000  61878.000000  61878.000000   \n","mean   ...      0.070752      0.532306      1.128576      0.393549   \n","std    ...      1.151460      1.900438      2.681554      1.575455   \n","min    ...      0.000000      0.000000      0.000000      0.000000   \n","25%    ...      0.000000      0.000000      0.000000      0.000000   \n","50%    ...      0.000000      0.000000      0.000000      0.000000   \n","75%    ...      0.000000      0.000000      1.000000      0.000000   \n","max    ...     76.000000     55.000000     65.000000     67.000000   \n","\n","            feat_88       feat_89       feat_90       feat_91       feat_92  \\\n","count  61878.000000  61878.000000  61878.000000  61878.000000  61878.000000   \n","mean       0.874915      0.457772      0.812421      0.264941      0.380119   \n","std        2.115466      1.527385      4.597804      2.045646      0.982385   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n","75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n","max       30.000000     61.000000    130.000000     52.000000     19.000000   \n","\n","            feat_93  \n","count  61878.000000  \n","mean       0.126135  \n","std        1.201720  \n","min        0.000000  \n","25%        0.000000  \n","50%        0.000000  \n","75%        0.000000  \n","max       87.000000  \n","\n","[8 rows x 94 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# summary statistics of numeric columns\n","data.describe()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#checking for null values\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","data.no"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"scatter() missing 1 required positional argument: 'y'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/ezra_analytics/Desktop/Moringa_projects/dsc-pca-and-pipelines-v2-1/index.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ezra_analytics/Desktop/Moringa_projects/dsc-pca-and-pipelines-v2-1/index.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ezra_analytics/Desktop/Moringa_projects/dsc-pca-and-pipelines-v2-1/index.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplot()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ezra_analytics/Desktop/Moringa_projects/dsc-pca-and-pipelines-v2-1/index.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(data)\n","\u001b[0;31mTypeError\u001b[0m: scatter() missing 1 required positional argument: 'y'"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Your code here\n","import matplotlib.pyplot as plt\n","fig = plt.subplot()"]},{"cell_type":"markdown","metadata":{},"source":["If you look at all the histograms, you can tell that a lot of the data are zero-inflated, so most of the variables contain mostly zeros and then some higher values here and there. No normality, but for most machine learning techniques this is not an issue. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["Because there are so many zeroes, most values above zero will seem to be outliers. The safe decision for this data is to not delete any outliers and see what happens. With many 0s, sparse data is available and high values may be super informative. Moreover, without having any intuitive meaning for each of the features, we don't know if a value of ~260 is actually an outlier."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["## Feature engineering and selection with PCA"]},{"cell_type":"markdown","metadata":{},"source":["Have a look at the correlation structure of your features using a [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["Use PCA to select a number of features in a way that you still keep 80% of your explained variance."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["## Create a train-test split with a test size of 40%\n","\n","This is a relatively big training set, so you can assign 40% to the test set. Set the `random_state` to 42. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["## Create a baseline model"]},{"cell_type":"markdown","metadata":{},"source":["Create your baseline model *in a pipeline setting*. In the pipeline: \n","\n","- Your first step will be to scale your features down to the number of features that ensure you keep just 80% of your explained variance (which we saw before)\n","- Your second step will be to build a basic logistic regression model \n","\n","Make sure to fit the model using the training set and test the result by obtaining the accuracy using the test set. Set the `random_state` to 123. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here"]},{"cell_type":"markdown","metadata":{},"source":["## Create a pipeline consisting of a linear SVM, a simple decision tree, and a simple random forest classifier"]},{"cell_type":"markdown","metadata":{},"source":["Repeat the above, but now create three different pipelines:\n","- One for a standard linear SVM\n","- One for a default decision tree\n","- One for a random forest classifier"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","# ⏰ This cell may take several minutes to run"]},{"cell_type":"markdown","metadata":{},"source":["## Pipeline with grid search"]},{"cell_type":"markdown","metadata":{},"source":["Construct two pipelines with grid search:\n","- one for random forests - try to have around 40 different models\n","- one for the AdaBoost algorithm "]},{"cell_type":"markdown","metadata":{},"source":["### Random Forest pipeline with grid search"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here \n","# imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","# ⏰ This cell may take a long time to run!\n"]},{"cell_type":"markdown","metadata":{},"source":["Use your grid search object along with `.cv_results` to get the full result overview"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here "]},{"cell_type":"markdown","metadata":{},"source":["### AdaBoost"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","# ⏰ This cell may take several minutes to run"]},{"cell_type":"markdown","metadata":{},"source":["Use your grid search object along with `.cv_results` to get the full result overview: "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here "]},{"cell_type":"markdown","metadata":{},"source":["### Level-up (Optional): SVM pipeline with grid search \n","\n","As extra level-up work, construct a pipeline with grid search for support vector machines. \n","* Make sure your grid isn't too big. You'll see it takes quite a while to fit SVMs with non-linear kernel functions!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here\n","# ⏰ This cell may take a very long time to run!"]},{"cell_type":"markdown","metadata":{},"source":["Use your grid search object along with `.cv_results` to get the full result overview: "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your code here "]},{"cell_type":"markdown","metadata":{},"source":["## Note\n","\n","Note that this solution is only one of many options. The results in the Random Forest and AdaBoost models show that there is a lot of improvement possible by tuning the hyperparameters further, so make sure to explore this yourself!"]},{"cell_type":"markdown","metadata":{},"source":["## Summary \n","\n","Great! You've gotten a lot of practice in using PCA in pipelines. What algorithm would you choose and why?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":2}
